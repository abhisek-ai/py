{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgPjQbmuGVdIE3t1DaNnl6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhisek-ai/py/blob/master/RSS_news_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y6YPg3aKEx_",
        "outputId": "ee26e724-5479-4359-c3b9-ba72cbb1ae58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.10/dist-packages (6.0.11)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install feedparser\n",
        "import feedparser\n",
        "from sqlalchemy import create_engine, Column, String, DateTime, Integer, text\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxvipfXGLQzS",
        "outputId": "f23887d1-25c7-4b7b-f21c-6adca019a9e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Base = declarative_base()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w9PHoFVLRwK",
        "outputId": "b6445ef4-e04c-49fd-944a-bc5cf076679b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9bae6e3862ba>:1: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base = declarative_base()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsArticle(Base):\n",
        "    __tablename__ = 'news_articles'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    title = Column(String)\n",
        "    content = Column(String)\n",
        "    pub_date = Column(DateTime)\n",
        "    source_url = Column(String)\n",
        "    category = Column(String)"
      ],
      "metadata": {
        "id": "D-KGTbJCLVbo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to SQLite in-memory database (for demonstration)\n",
        "engine = create_engine('sqlite:///:memory:')\n",
        "Base.metadata.create_all(engine)"
      ],
      "metadata": {
        "id": "6a6C0f4tLYAR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Session = sessionmaker(bind=engine)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "-VZreCfnLbpO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [ps.stem(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)"
      ],
      "metadata": {
        "id": "hWtCK_SdLecy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_category(text):\n",
        "    # Implement your own classification logic here using NLTK or spaCy\n",
        "    # This is a placeholder\n",
        "    return 'Positive/Uplifting'"
      ],
      "metadata": {
        "id": "f0eOzcCxLg7g"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_article(session, article_data):\n",
        "    try:\n",
        "        article = NewsArticle(**article_data)\n",
        "        session.add(article)\n",
        "        session.commit()\n",
        "\n",
        "        # Perform NLP classification\n",
        "        processed_content = process_text(article.content)\n",
        "        category = classify_category(processed_content)\n",
        "\n",
        "        article.category = category\n",
        "        session.commit()\n",
        "    except Exception as e:\n",
        "        # Handle errors and log appropriately\n",
        "        print(f\"Error processing article: {e}\")"
      ],
      "metadata": {
        "id": "696RWVegLjIp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "\n",
        "rss_feed = 'http://rss.cnn.com/rss/cnn_topstories.rss'\n",
        "feed = feedparser.parse(rss_feed)\n",
        "\n",
        "for entry in feed.entries:\n",
        "    # Check if 'published' exists in the entry\n",
        "    if 'published' in entry:\n",
        "        pub_date = entry.published\n",
        "    else:\n",
        "        pub_date = None\n",
        "\n",
        "    # Check if 'summary' exists in the entry\n",
        "    if 'summary' in entry:\n",
        "        summary = entry.summary\n",
        "    else:\n",
        "        summary = None\n",
        "\n",
        "    article_data = {\n",
        "        'title': entry.title,\n",
        "        'content': summary,\n",
        "        'pub_date': pub_date,\n",
        "        'source_url': entry.link,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "oEPk19GvLokb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the database for results\n",
        "result = session.query(NewsArticle).all()\n",
        "for article in result:\n",
        "    print(article.title, article.category)\n",
        "\n",
        "session.close()"
      ],
      "metadata": {
        "id": "Vu-FDbUkLrkz"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}